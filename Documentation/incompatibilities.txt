Closures

	in pyvm closures are bound *once* at the function definition
	just like default arguments. (the only exception is a closure
	that references itself and the function is bound into the
	closures *after* its creation).

	The logic for this is that with closures we have some kind of
	references to variables.  Python doesn't have references to
	variables and many times newbies complain, but in the end they
	learn the pythonic way which is that we don't need references.
	And some times people use closures just so they can have
	references to variables!

	So IMO, we'd either go for full writable closures or the
	"half-closures"[*] which are bound like default arguments.

	From the examples that use closures that I've studied,
	most are ok with half-closures (~80%). (closures where invented
	to avoid the extra typing in cases like:
		def foo (self):
	    		return lambda s=self: s.bar()+1
	). In the other cases the conversion is very easy and the
	compiler can warn if it sees that a closure is modified in
	the outer function after the definition of the nested function.

	In any case, if one wants a writable closure *or* a closure
	which can be modified by the outer function after the creation
	of the nested function, they can reference it in a list:

		def foo ():
		    CLOSURE = [None]
		    def nested (y):
		        print CLOSURE [0]
	        	if y:
		            CLOSURE [0] = y    # writable closure
		    CLOSURE [0] = 13   # modify after creation of nested
		    return nested

	...where the real closure is the list referencing the value.

	This way we can also discard the opcodes LOAD_CLOSURE, LOAD_DEREF,
	STORE_DEREF and do everything with LOAD_FAST.



	[*] For the code:

	def foo ():
	    L = []
	    for i in range (10):
	        L.append (lambda :i)
	    return L

	for x in foo():
	    print x(),

	With the current closures you get
	 9 9 9 9 9 9 9 9 9 9
	While with "half-closures" you get:
	 0 1 2 3 4 5 6 7 8 9

	and if you sum() that you'll get half result.


MISC:

Q: Can pyvm run .pyc files generated by CPython?

A: In 99% of the cases yes.  There is one incompatibility:
   pyvm needs a special placement of exceptions in the stack
   in order to use sys.exc_info and "raise" without arguments
   (re-raise last exception).  For bytecode generated with
   CPython's internal compiler that doesn't happen and those
   two features will bring down the vm (actually error messages
   will be wrong and non-informative).
   On the other hand, none of the py files included in the
   toolchain use this feature so they can be used safely even
   if compiled with CPython.
   Tkinter and SocketServer use this to report errors so if
   you are working with these modules, remember to recompile
   them with pyc if you're getting weird error messages.

   Another problem is 'exec'. pyvm's EXEC_STMT doesn't work
   very well. The pyc compiler will use the __exec__() builtin
   function instead.

   TODO: the right right thing would be to "mirror" python's
   standard library: have a directory toolchain/tmp/mirror
   where we generate pycs for each file that belongs in
   python's standard library.

Q: But I get errors with GL

A: That's another problem.  When CPython sees an integer
   LONG_MAX < x < ULONG_MAX, (iow something that fits in
   32-bits but is a negative number in signed), it will
   save it as an infinite-digit-number.  pyvm stores those
   as ints.  So GLCONSTS must be compiled with pyc and
   marshalled with pyvm in order to remain an int.
   (pyc executed with pyvm).

Q: When I try to run a .py file I get 'KeyBoardError' or
   something similar and completely irrelevant!

A: There is a syntax error in the .py file you are trying
   to compile and the pyc compiler doesn't handle it correctly
   and raises irrelevant stuff.  Just run "python file.py"
   and let python's compiler find the syntax error.
